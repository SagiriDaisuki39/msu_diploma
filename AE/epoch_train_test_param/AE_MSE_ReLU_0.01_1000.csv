epoch,train_loss,test_loss
1,0.1683395355939865,0.1683853268623352
2,0.1678665429353714,0.16796067357063293
3,0.16777002811431885,0.16796067357063293
4,0.1677723526954651,0.16796067357063293
5,0.1677878499031067,0.16796067357063293
6,0.16777540743350983,0.16796067357063293
7,0.16777686774730682,0.16796067357063293
8,0.1677679717540741,0.16796067357063293
9,0.1677640676498413,0.16796067357063293
10,0.16777285933494568,0.16796067357063293
11,0.16777753829956055,0.16796067357063293
12,0.1677759885787964,0.16796067357063293
13,0.16777512431144714,0.16796067357063293
14,0.1677767038345337,0.16796067357063293
15,0.1677664816379547,0.16796067357063293
16,0.16777311265468597,0.16796067357063293
17,0.16778913140296936,0.16796067357063293
18,0.16777187585830688,0.16796067357063293
19,0.16777224838733673,0.16796067357063293
20,0.16778568923473358,0.16796067357063293
21,0.16777485609054565,0.16796067357063293
22,0.16777350008487701,0.16796067357063293
23,0.16776786744594574,0.16796067357063293
24,0.17846989631652832,0.19444230198860168
25,0.19421111047267914,0.19435544312000275
26,0.19417935609817505,0.19435544312000275
27,0.19417932629585266,0.19435544312000275
28,0.19418780505657196,0.19435544312000275
29,0.19417360424995422,0.19435544312000275
30,0.1941869854927063,0.19435544312000275
31,0.19417066872119904,0.19435544312000275
32,0.19418132305145264,0.19435544312000275
33,0.19417783617973328,0.19435544312000275
34,0.19417455792427063,0.19435544312000275
35,0.19418837130069733,0.19435544312000275
