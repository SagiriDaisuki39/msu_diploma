epoch,train_loss,test_loss
1,0.1659063696861267,0.1666117161512375
2,0.16609039902687073,0.1666117161512375
3,0.1661122590303421,0.1666678488254547
4,0.16613642871379852,0.1666678488254547
5,0.16613350808620453,0.1666678488254547
6,0.16613857448101044,0.1666678488254547
7,0.16614225506782532,0.1666678488254547
8,0.16614404320716858,0.16667452454566956
9,0.1661500781774521,0.16667452454566956
10,0.1661393940448761,0.16667452454566956
11,0.1661520153284073,0.16667452454566956
12,0.16614392399787903,0.16667452454566956
13,0.16614478826522827,0.16667452454566956
14,0.16614900529384613,0.16667452454566956
15,0.16614505648612976,0.16667452454566956
16,0.16614313423633575,0.16667452454566956
17,0.16614438593387604,0.16667452454566956
18,0.16614359617233276,0.16667452454566956
19,0.16614577174186707,0.16667452454566956
20,0.16616100072860718,0.16667452454566956
21,0.1661590337753296,0.16667452454566956
22,0.16614779829978943,0.16667452454566956
23,0.16614484786987305,0.16667452454566956
24,0.1661514937877655,0.16667452454566956
25,0.1661486178636551,0.16667452454566956
26,0.16614185273647308,0.16667452454566956
27,0.16614775359630585,0.16667452454566956
28,0.1661447286605835,0.16667452454566956
29,0.16615203022956848,0.16667452454566956
30,0.1661379039287567,0.16667452454566956
31,0.16614247858524323,0.16667452454566956
32,0.1661490648984909,0.16667452454566956
33,0.16614995896816254,0.16667452454566956
34,0.16614732146263123,0.16667452454566956
35,0.16615092754364014,0.16667452454566956
