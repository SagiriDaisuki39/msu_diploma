epoch,train_loss,test_loss
1,0.1661020815372467,0.16623389720916748
2,0.16583287715911865,0.16623389720916748
3,0.1658402383327484,0.16623389720916748
4,0.1658441722393036,0.16623389720916748
5,0.16584789752960205,0.16623389720916748
6,0.16586698591709137,0.1663150042295456
7,0.1659480780363083,0.1663150042295456
8,0.16594985127449036,0.1663150042295456
9,0.16595670580863953,0.1663150042295456
10,0.16594566404819489,0.1663150042295456
11,0.1659460961818695,0.1663150042295456
12,0.1659419685602188,0.1663150042295456
13,0.16594259440898895,0.1663150042295456
14,0.1659393310546875,0.1663150042295456
15,0.16596098244190216,0.1663150042295456
16,0.18303553760051727,0.18778878450393677
17,0.18412713706493378,0.1834179162979126
18,0.18362495303153992,0.18282672762870789
19,0.18226486444473267,0.1819576770067215
20,0.18119758367538452,0.18114840984344482
21,0.18075494468212128,0.18092092871665955
22,0.18074360489845276,0.18111737072467804
23,0.18077817559242249,0.1810830980539322
24,0.1806991696357727,0.1807502806186676
25,0.18047647178173065,0.18077997863292694
26,0.18048274517059326,0.18074378371238708
27,0.18049827218055725,0.18080773949623108
28,0.1805211752653122,0.18081587553024292
29,0.1806408315896988,0.18125475943088531
30,0.18097135424613953,0.18125897645950317
31,0.18109911680221558,0.18146590888500214
32,0.1806338131427765,0.1802854835987091
33,0.18017689883708954,0.18047885596752167
34,0.1803462654352188,0.1805281639099121
35,0.18017148971557617,0.18063591420650482
