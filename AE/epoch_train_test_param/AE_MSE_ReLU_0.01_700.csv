epoch,train_loss,test_loss
1,0.16042669117450714,0.1612004041671753
2,0.16064350306987762,0.1612265259027481
3,0.16065028309822083,0.1612265259027481
4,0.16064979135990143,0.1612265259027481
5,0.16064824163913727,0.1612265259027481
6,0.1606459617614746,0.1612265259027481
7,0.16064777970314026,0.1612265259027481
8,0.1606433242559433,0.1612265259027481
9,0.160652294754982,0.1612265259027481
10,0.16065645217895508,0.1612265259027481
11,0.16064395010471344,0.1612265259027481
12,0.16064447164535522,0.1612265259027481
13,0.16064654290676117,0.1612265259027481
14,0.16065040230751038,0.1612265259027481
15,0.16064783930778503,0.1612265259027481
16,0.1606442928314209,0.1612265259027481
17,0.16064195334911346,0.1612265259027481
18,0.1606525331735611,0.1612265259027481
19,0.1606498509645462,0.1612265259027481
20,0.1606401950120926,0.1612265259027481
21,0.16064390540122986,0.1612265259027481
22,0.16064439713954926,0.1612265259027481
23,0.16064977645874023,0.1612265259027481
24,0.16065169870853424,0.1612265259027481
25,0.16065295040607452,0.1612265259027481
26,0.16064828634262085,0.1612265259027481
27,0.16066530346870422,0.1612265259027481
28,0.16065780818462372,0.1612265259027481
29,0.16795875132083893,0.1722630113363266
30,0.17090141773223877,0.1712125688791275
31,0.17101570963859558,0.17120739817619324
32,0.17129072546958923,0.17162322998046875
33,0.171524316072464,0.17172078788280487
34,0.1715812087059021,0.17172707617282867
35,0.17212924361228943,0.17254391312599182
