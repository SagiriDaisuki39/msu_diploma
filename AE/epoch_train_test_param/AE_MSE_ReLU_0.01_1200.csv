epoch,train_loss,test_loss
1,0.16434243321418762,0.16738688945770264
2,0.1674395054578781,0.16871695220470428
3,0.16831259429454803,0.16871695220470428
4,0.16830812394618988,0.16871695220470428
5,0.16830800473690033,0.16871695220470428
6,0.16832344233989716,0.16871695220470428
7,0.16830413043498993,0.16871695220470428
8,0.168303981423378,0.16871695220470428
9,0.16831782460212708,0.16871695220470428
10,0.16831263899803162,0.16871695220470428
11,0.16831691563129425,0.16871695220470428
12,0.16830278933048248,0.16871695220470428
13,0.16831715404987335,0.16871695220470428
14,0.16829729080200195,0.16871695220470428
15,0.16830898821353912,0.16871695220470428
16,0.1683129072189331,0.16871695220470428
17,0.16830378770828247,0.16871695220470428
18,0.16830740869045258,0.16871695220470428
19,0.1683097630739212,0.16871695220470428
20,0.1683119535446167,0.16871695220470428
21,0.16829745471477509,0.16871695220470428
22,0.16829854249954224,0.16871695220470428
23,0.16830185055732727,0.16871695220470428
24,0.16830669343471527,0.16871695220470428
25,0.16829374432563782,0.16871695220470428
26,0.16831199824810028,0.16871695220470428
27,0.1683051437139511,0.16871695220470428
28,0.16830949485301971,0.16871695220470428
29,0.16830462217330933,0.16871695220470428
30,0.16829988360404968,0.16871695220470428
31,0.16831842064857483,0.16871695220470428
32,0.1682920902967453,0.16871695220470428
33,0.16831235587596893,0.16871695220470428
34,0.16830794513225555,0.16871695220470428
35,0.16830579936504364,0.16871695220470428
