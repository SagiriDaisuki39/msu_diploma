epoch,train_loss,test_loss
1,0.16404272615909576,0.16388623416423798
2,0.16366349160671234,0.16388623416423798
3,0.16365890204906464,0.16388623416423798
4,0.16364231705665588,0.16388623416423798
5,0.16489896178245544,0.1656913161277771
6,0.1654478758573532,0.1656913161277771
7,0.16546708345413208,0.1656913161277771
8,0.165479376912117,0.1656913161277771
9,0.16546602547168732,0.1656913161277771
10,0.16544444859027863,0.1656913161277771
11,0.16546553373336792,0.1656913161277771
12,0.16546761989593506,0.1656913161277771
13,0.165451318025589,0.1656913161277771
14,0.16544479131698608,0.1656913161277771
15,0.16545851528644562,0.1656913161277771
16,0.1654582917690277,0.1656913161277771
17,0.16545456647872925,0.1656913161277771
18,0.1654619723558426,0.1656913161277771
19,0.16545845568180084,0.1656913161277771
20,0.16545385122299194,0.1656913161277771
21,0.1654473841190338,0.1656913161277771
22,0.16545577347278595,0.1656913161277771
23,0.16546744108200073,0.1656913161277771
24,0.16546688973903656,0.1656913161277771
25,0.16547003388404846,0.1656913161277771
26,0.1654776781797409,0.1656913161277771
27,0.1654599905014038,0.1656913161277771
28,0.1654583066701889,0.1656913161277771
29,0.16544672846794128,0.1656913161277771
30,0.1654529571533203,0.1656913161277771
31,0.16546453535556793,0.1656913161277771
32,0.16545338928699493,0.1656913161277771
33,0.16544683277606964,0.1656913161277771
34,0.16546614468097687,0.1656913161277771
35,0.1654534637928009,0.1656913161277771
