epoch,train_loss,test_loss
1,0.1650974154472351,0.16534490883350372
2,0.16510382294654846,0.16534490883350372
3,0.1651051938533783,0.16534490883350372
4,0.16512177884578705,0.16534490883350372
5,0.1651104986667633,0.16534490883350372
6,0.16511443257331848,0.16534490883350372
7,0.1651078462600708,0.16534490883350372
8,0.16510939598083496,0.16534490883350372
9,0.16512414813041687,0.16534490883350372
10,0.16511017084121704,0.16534490883350372
11,0.16511066257953644,0.16534490883350372
12,0.17035476863384247,0.1747518926858902
13,0.18937747180461884,0.1878291368484497
14,0.1854553073644638,0.18413718044757843
15,0.18442609906196594,0.18479470908641815
16,0.18556243181228638,0.18598656356334686
17,0.18573778867721558,0.18675634264945984
18,0.18721164762973785,0.18862105906009674
19,0.18831780552864075,0.18762759864330292
20,0.18682469427585602,0.18677204847335815
21,0.18656909465789795,0.18637444078922272
22,0.18596702814102173,0.1863059550523758
23,0.185737743973732,0.1860084980726242
24,0.18602266907691956,0.18634620308876038
25,0.18595004081726074,0.18629947304725647
26,0.18597912788391113,0.1863122284412384
27,0.18599233031272888,0.18642112612724304
28,0.18610328435897827,0.18616518378257751
29,0.18568481504917145,0.1862478405237198
30,0.1840551346540451,0.18076160550117493
31,0.1804969310760498,0.18029145896434784
32,0.18031877279281616,0.180120587348938
33,0.17910629510879517,0.17819282412528992
34,0.17742162942886353,0.1772850602865219
35,0.17694014310836792,0.17716826498508453
